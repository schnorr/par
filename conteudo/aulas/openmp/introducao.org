# -*- coding: utf-8 -*-
# -*- mode: org -*-
#+startup: beamer overview indent
#+LANGUAGE: pt-br
#+TAGS: noexport(n)
#+EXPORT_EXCLUDE_TAGS: noexport
#+EXPORT_SELECT_TAGS: export

#+Title: OpenMP
#+Author: Prof. Lucas M. Schnorr (UFRGS)
#+Date: \copyleft

#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [xcolor=dvipsnames]
#+OPTIONS:   H:1 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+LATEX_HEADER: \input{../org-babel.tex}
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}

* Introdução
Segue o modelo SPMD -- Single Program Multiple Data
+ Um único código executado com dados diferentes
Norma OpenMP
+ Implementações em memória compartilhada
+ *Paralelismo de laços*
    + Explícito, tipo fork-join
+ Especificação alto-nível (sobre threads)
+ Usa diretivas de compilação
    #+BEGIN_SRC C
    #pragma omp ...
    #+END_SRC
#+latex: \vfill
\pause  Observações
+ Fácil obter o código sequencial
+ Suporte em C, C++, Fortran, ...
+ OpenMP: __Compilador compatível + runtime__

* Disponibilidade
Consórcio de fabricantes HW/SW
+ HP, IBM, Intel, SGI
Compiladores compatíveis
+ gcc -- https://gcc.gnu.org/wiki/openmp
+ clang -- https://clang-omp.github.io/
+ Lista completa: \\ http://openmp.org/wp/openmp-compilers/
#+latex: \vfill
\pause  Testar com um olá mundo
  \tiny
  #+BEGIN_SRC C
#include <omp.h>
#include <stdio.h>
int main() {
#pragma omp parallel
    printf("Hello from thread %d, nthreads %d\n",
            omp_get_thread_num(), omp_get_num_threads());
}
  #+END_SRC
\pause Em um Debian
  #+BEGIN_SRC C
  gcc -fopenmp hello.c
  #+END_SRC
#+latex: \vfill
* Paralelização em OpenMP
Identifique os laços *custosos*
  #+BEGIN_SRC C
double res[MAX];
for (i = 0; i < MAX; i++)
   calculo_pesado(&res[i]);
  #+END_SRC
#+latex: \vfill
\pause  Versão paralelizada com OpenMP
  #+BEGIN_SRC C
double res[MAX];
#pragma omp parallel for
for (i = 0; i < MAX; i++)
   calculo_pesado(&res[i]);    
  #+END_SRC
* Comunicação entre fluxos de execução
Via memória compartilhada
+ Possibilidade de definir quais variáveis são compartilhadas
Necessidade de sincronizar os acessos
+ Implica em sobrecusto (escondido do programador)
+ \pause  Bom projeto do algoritmo
    + Distribuição de dados
    + Volume de acessos remoto
* Diretivas OpenMP (5 categorias)
Regiões paralelas
  #+BEGIN_SRC C
  omp parallel
  #+END_SRC
\pause  Compartilhamento dos dados
  #+BEGIN_SRC C
  omp shared, private
  #+END_SRC
\pause  Distribuição de trabalho
  #+BEGIN_SRC C
  omp for
  #+END_SRC
\pause  Sincronizações
  #+BEGIN_SRC C
  omp atomic, critical, barrier
  #+END_SRC
\pause  Funções para tempo de execução, variáveis de ambiente
  #+BEGIN_SRC C
  omp_set_num_threads()
  omp_set_lock(), ...
  OMP_SCHEDULE, OMP_NUM_THREADS, ...
  #+END_SRC
* Regiões Paralelas
Criação de fluxos de execução
  #+BEGIN_SRC C
double A[10000];
#pragma omp parallel
{
   int th_id = omp_get_thread_num();
   calculo_pesado(th_id, A);
}
  #+END_SRC
\pause  Observações
+ Abertura de chaves sinaliza fork das threads
+ Fechamento de chaves indica join
+ Variável A é compartilhada
* Compartilhamento dos dados
Variáveis compartilhadas
+ Estáticas
+ Globais
Variáveis privadas a cada fluxo
+ Locais a um bloco
+ Alocadas na pilha do fluxo paralelo
    + Exemplo: função chamada por uma seção paralela
* Definir compartilhamento diferenciado
Existem cláusulas que dão liberdade ao programador
+ Permite especificar o que compartilhar
\pause  Completam as diretivas
  #+BEGIN_SRC C
  omp parallel
  omp sections
  omp for
  #+END_SRC
#+latex: \vfill
\pause  São elas
+ shared(var) -- especifica que var é compartilhada
+ private(var) -- especifica que var é privada
    + Cria-se uma cópia privada em cada fluxo
+ default(private), default(shared)
* Distribuição de trabalho em um laço
O laço *for* pode ser paralelizado
  #+BEGIN_SRC C
int i;
#pragma omp parallel
#pragma omp for
for (i = 0; i < MAX; i++)
   calculo_pesado(i);
  #+END_SRC
\pause  Observações
+ Unidade de trabalho é uma iteração
+ Barreira de sincronização no final do laço
+ Como fazer a distribuição das iterações para os fluxos?
    + Diretiva *schedule*
* Exemplo de escalonamento, parte 1
Temos 14 iterações, a distribuir em 3 fluxos

#+ATTR_LATEX: :width \linewidth
[[./openmp_schedule_0.png]]

#+latex: \vfill

\pause  Distribuição por blocos

#+ATTR_LATEX: :width \linewidth
[[./openmp_schedule_1.png]]

+ Boa localidade, balanceamento ruim
* Exemplo de escalonamento, parte 2
Distribuição puramente cíclica

#+ATTR_LATEX: :width \linewidth
[[./openmp_schedule_2.png]]

+ Localidade ruim, bom balanceamento
#+latex: \vfill
\pause  Distribuição por blocos, mas cíclica

#+ATTR_LATEX: :width \linewidth
[[./openmp_schedule_3.png]]

+ Localidade e balanceamento se encontram
* Discussão sobre escalonamento
Forma da distribuição das iterações
+ Influencia na *granularidade do trabalho* dos fluxos
#+latex: \vfill
\pause  Iterações com tempos diferentes

\pause  Bloco maior \rightarrow melhor localidade espacial

\pause  Bloco menor \rightarrow melhor balanceamento de carga
#+latex: \vfill
\pause  Encontrar um bom equilíbrio?
+ Execuções experimentais
+ Análise de desempenho
+ Fixo?
* Diretiva de escalonamento -- omp for schedule
*omp for schedule (static [, chunk])*
+ Distribuição estática das iterações por bloco
    + Tamanho do bloco é *chunk*
\pause  *omp for schedule (dynamic [, chunk])*
+ Distribuição dinâmica (cíclica)
\pause  *omp for schedule (guided [, chunk])*
+ Distribuição estática
+ Tamanho do bloco diminui a medida que o cálculo anda
\pause  *omp for schedule (runtime)*
+ Definido em tempo de execução
    + Variável de ambiente *OMP_SCHEDULE*
* Exemplo comparativo
omp parallel
  \small
  #+BEGIN_SRC C
    #pragma omp parallel
    {
      int th = omp_get_thread_num();
      int nth = omp_get_num_threads();
      int inicio = th * MAX / nth;
      int fim = (th+1) * MAX / nth;
      for (i = inicio; i < fim; i++)
        a[i] = a[i] + b[i];
    }     
  #+END_SRC
\normalsize
\pause  omp for
  \small
  #+BEGIN_SRC C
#pragma omp parallel
#pragma omp for schedule(static)
for (i = 0; i < MAX; i++)
  a[i] = a[i] + b[i]
  #+END_SRC
* Diferenças de compartilhamento privado
#+BEGIN_SRC C
 int i = 10;
 #pragma omp parallel private(i)
 {
     printf("th %d: i = %d\n", omp_get_thread_num(), i);
     i = 1000 + omp_get_thread_num();
 }
 printf("i = %d\n", i);   
#+END_SRC
#+latex: \vfill
\pause  Valor inicial de variáveis privadas é aleatório

\pause  Modificações na região paralela não são visíveis fora dela
* Inicializando e Exportando uma variável privada
*firstprivate* é utilizada para inicializar variáveis privadas
  #+BEGIN_SRC C
 int i = 10;
 #pragma omp parallel firstprivate(i)
 {
     printf("th %d: i=%d\n", omp_get_thread_num(), i);
     i = 1000 + omp_get_thread_num();
 }
 printf("i = %d\n", i);   
  #+END_SRC
#+latex: \vfill
\pause  Modificações na região paralela não são visíveis fora dela
+ *lastprivate* exporta o valor da __última iteração do laço__
* Exemplo com private, firstprivate, lastprivate
Qual o valor impresso no printf caso
+ private(soma)
+ firstprivate(soma)
+ lastprivate(soma)
+ firstprivate(soma) lastprivate(soma)
  #+BEGIN_SRC C
  int soma = 0;
#pragma omp parallel for schedule (static)
#pragma omp private(soma)
  for (i=0; i < MAX; i++) {
 soma += i;
  }
  printf ("soma = %d\n", soma);
  #+END_SRC
#+latex: \vfill
\pause  Qual operações nós precisamos para este algoritmo?
* Operadores sobre variáveis privadas
Cláusula *reduction (op : list)*
+ *op* é uma operação, exemplo a soma '+'
+ *list* é uma lista de variáveis
#+latex: \vfill
\pause  Cada fluxo tem uma cópia inicializada

\pause  Operação é feita no ponto de sincronização (join)

\pause  Atribuído para a variável ``global''
#+latex: \vfill
Vejamos um exemplo em __reduction.c__
